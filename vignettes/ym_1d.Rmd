---
title: "YM-1D.Rmd"
author: "Dylan Stark"
date: "3/7/2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(tidytext)
library(modelr)

library(courseraswiftkey)
```

YM-1D is a 4-gram language model.
This report includes evaluations of uni-, bi-, and tri-grams, also.
All models are trained and evaluated against the each US English corpus separately.

## Data

Load available data.

```{r}
data("en_us_news")
data("en_us_twitter")
data("en_us_blogs")
```

Generate train-test-validate split.
Use `down_sample` rate to tune amount of corpus data to use.
Table (`tbl`) contains original data, sample, and randomized partitions.

```{r}
set.seed(42)

down_sample <- 0.01

# Partition data frame into random 80:10:10 split and return as a wide
# data frame (tibble).
spread_resample <- function(data) {
  data  %>%
    resample_partition(c(train = 0.80, validate = 0.10, test = 0.10)) %>%
    enframe() %>%
    spread(name, value)
}

tbl <- tribble(
  ~desc, ~data,
  "news", en_us_news,
  "blogs", en_us_blogs,
  "twitter", en_us_twitter
) %>%
  mutate(
    sample = map(data, sample_frac, down_sample),
    resample = map(sample, spread_resample)
  ) %>%
  unnest(resample)
```

## Unigram Model

The unigram model selects the next word from the set of known words with probability proportional to how frequent the word appeared in the training corpus.

```{r}
unigram_tbl <- tbl %>%
  select(desc, train, validate) %>%
  mutate(
    train = map(train, as.data.frame),
    validate = map(validate, as.data.frame),
    unigram_model = map(train, build_unigram_model)
  )
```

### Example suggestions

Example suggestions from news corpus.

```{r}
unigram_tbl[1, "unigram_model"][[1, 1]] %>%
  sample_n(3, weight = prob) %>%
  arrange(desc(prob))
```

Example suggestions from blogs corpus.

```{r}
unigram_tbl[2, "unigram_model"][[1, 1]] %>%
  sample_n(3, weight = prob) %>%
  arrange(desc(prob))
```

Example suggestions from twitter corpus.

```{r}
unigram_tbl[3, "unigram_model"][[1, 1]] %>%
  sample_n(3, weight = prob) %>%
  arrange(desc(prob))
```

### Evaluation

For each word in the validation set, predict the word using the unigram model.
This is equivalent to generating a sample from the model that is the same size as the validation set (word count).

Accuracy is measured as the proportion of correct predictions.

```{r}
predict_unigram_top_n <- function(word, model, n) {
  model %>%
    arrange(desc(prob)) %>%
    head(n) %>%
    sample_n(1, weight = prob) %>%
    .[[1, "w1"]]
}

predict_unigram_weighted <- function(word, model, n) {
  predict_unigram_top_n(word, model, n = nrow(model))
}

predict_unigram_top <- function(word, model, n) {
  predict_unigram_top_n(word, model, n = 1)
}

predict <- function(model, data, .f, n) {
  data %>%
    unnest_tokens(w1, text) %>%
    mutate(y1 = map_chr(w1, .f, model = model, n = n),
           match = w1 == y1) %>%
    summarize(accuracy = sum(match) / n()) %>%
    .[["accuracy"]]
}
```

```{r}
unigram_tbl %>%
  mutate(weighted_acc = map2_dbl(unigram_model, validate, predict, predict_unigram_weighted),
         top_acc = map2_dbl(unigram_model, validate, predict, predict_unigram_top),
         top_10_acc = map2_dbl(unigram_model, validate, predict, predict_unigram_top_n, n = 10)) %>%
  select(-train, -validate, -unigram_model)
```

Choosing the top most-frequent word from the training set is more accurate than randomly choosing from a weighted distribution, though that accuracy is very bad.


## Bigram Model

The bigram model selects the next word based on preceding word.

We add a `_s_start` token to the beginning of each entry in the training dataset to caputure the beginning word in a `(_s_start, <word>)` tuple.

We also insert `_s_unk` tokens so that our model can work with out-of-vocabulary words (i.e., words not seen in the training data set).
We have to do this because our model uses one word-worth of context.

```{r}
add_start_token <- function(data, start = "_s_start") {
  data %>%
    mutate(text = paste(start, text))
}

add_unknowns <- function(data, symbol = "_s_unk") {
  data %>%
    unnest_tokens(word, text) %>%
    group_by(word) %>%
    mutate(word2 = lag(word, n = 1, default = symbol)) %>%
    group_by(line) %>%
    summarize(text = paste(word2, collapse = " "))
}

count_bigrams <- function(data) {
  data %>%
    unnest_tokens(pair, text, token = "ngrams", n = 2, collapse = FALSE) %>%
    separate(pair, into = c("w1", "w2"), sep = " ", remove = FALSE) %>%
    count(w1, w2) %>%
    ungroup()
}

build_bigram_model <- function(data, k = 1.0) {
  data <- data %>%
    add_start_token() %>%
    add_unknowns()
  
  word_counts <- count_words(data)
  bigram_counts <- count_bigrams(data)
  
  V <- nrow(word_counts)
  
  bigram_counts %>%
    inner_join(word_counts, by = c("w1")) %>%
    rename(c1 = n.y, c2 = n.x) %>%
    mutate(prob = (c2 + k) / (c1 + k * V)) %>%
    ungroup()
}

bigram_tbl <- tbl %>%
  select(desc, train, validate) %>%
  mutate(
    train = map(train, as.data.frame),
    validate = map(validate, as.data.frame),
    bigram_model = map(train, build_bigram_model, k = 0.001)
  )
```

### Example suggestions

Example suggestions from news corpus.

```{r}
bigram_tbl[1, "bigram_model"][[1, 1]] %>%
  sample_n(3, weight = prob) %>%
  arrange(desc(prob))
```

Example suggestions from blogs corpus.

```{r}
bigram_tbl[2, "bigram_model"][[1, 1]] %>%
  sample_n(3, weight = prob) %>%
  arrange(desc(prob))
```

Example suggestions from news corpus.

```{r}
bigram_tbl[1, "bigram_model"][[1, 1]] %>%
  sample_n(3, weight = prob) %>%
  arrange(desc(prob))
```


### Evaluation

For each pair of words (including the `(_s_start, <word>)` tuple) in the validation set, predict the second word using the bigram model.

Accuracy is measured as the proportion of correct predictions.

```{r}
predict_unigram_top_n <- function(word, model, n) {
  model %>%
    arrange(desc(prob)) %>%
    head(n) %>%
    sample_n(1, weight = prob) %>%
    .[[1, "w1"]]
}

predict_unigram_weighted <- function(word, model, n) {
  predict_unigram_top_n(word, model, n = nrow(model))
}

predict_unigram_top <- function(word, model, n) {
  predict_unigram_top_n(word, model, n = 1)
}

predict_bigram <- function(model, data) {
  predict_bigram_ <- function(model, word) {
    exact_match <- model %>%
      filter(w1 == word & w2 != "_s_unk") %>%
      arrange(desc(prob))
    if (nrow(exact_match) > 0) {
      return(exact_match[[1, "w2"]])
    }
    
    unk_match <- model %>%
      filter(w1 == '_s_unk' & w2 != "_s_unk") %>%
      arrange(desc(prob))
    return(unk_match[[1, "w2"]])
  }
  
  data %>%
    add_start_token() %>%
    unnest_tokens(pair, text, token = "ngrams", n = 2) %>%
    separate(pair, into = c("w1", "w2"), sep = " ") %>%
    mutate(y2 = map_chr(w1, predict_bigram_, model = model),
           match = w2 == y2) %>%
    summarize(accuracy = sum(match) / n()) %>%
    .[["accuracy"]]
}
```

```{r}
bigram_tbl %>%
  mutate(acc = map2_dbl(bigram_model, validate, predict_bigram)) %>%
  select(-train, -validate, -bigram_model)
```

Accuracy is still fairly poor across the board.
