---
title: "YM-KN"
author: "Dylan Stark"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{YM-KN}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r}
library(tidyverse)
library(stringr)
library(tidytext)

library(courseraswiftkey)
```

```{r}
data("en_us_news")

ex_en <- en_us_news %>%
  head(100)
```

Implementation of [Kneser-Ney smoothing](https://en.wikipedia.org/wiki/Kneser%E2%80%93Ney_smoothing).

Discount: $\delta$

```{r}
delta <- 0.80
```

Vocab. with "_s_unk".

```{r}
vocab <- ex_en %>%
  unnest_tokens(word, text) %>%
  distinct(word) %>%
  rbind(data.frame(word = c("_s_unk")))
vocab %>%
  head()
```

## Unigram

```{r}
uni_en <- ex_en %>%
  unnest_tokens(pair, text, token = "ngrams", n = 2) %>%
  mutate(prefix = word(pair, 1),
         word = word(pair, -1)) %>%
  select(-line, -pair)
uni_en %>%
  head()
```

Continuation counts is the number of single-word contexts for $w_i \in V$: $cc_{KN}(w_i) = |\{w_{i-1} : C(w_{i-1}w_i) > 0\}|$

```{r}
cont_counts <- vocab %>%
  left_join(uni_en, by = c("word")) %>%
  distinct(prefix, word) %>%
  mutate(cont_count = ifelse(is.na(prefix), 0, 1)) %>%
  group_by(word) %>%
  summarize(num_distinct_context = sum(cont_count))
cont_counts %>%
  arrange(desc(num_distinct_context)) %>%
  head()

#cont_counts %>%
#  filter(num_distinct_context > delta) %>%
#  left_join(uni_num_distinct_pairs, by = c("word")) %>%
#  mutate(x = delta * num_distinct_context / num_distinct_pairs) %>%
#  summarize(y = sum(x))
```



Number of distinct contexts this word occurs in: $|\{w\prime : 0 < c(w\prime, w_i)\}|$

```{r}
#uni_distinct_context <- uni_en %>%
#  distinct(prefix, word) %>%
#  group_by(word) %>%
#  summarize(num_distinct_context = n())
#uni_distinct_context %>%
#  arrange(desc(num_distinct_context))
```

Number of distinct pairs of words: $|\{(w\prime, w\prime\prime) : 0 < c(w\prime, w\prime\prime)\}|$

```{r}
uni_num_distinct_pairs <- vocab %>%
  left_join(uni_en, by = c("word")) %>%
  distinct(prefix, word) %>%
  mutate(count = ifelse(is.na(prefix), 0, 1)) %>%
  mutate(num_distinct_pairs = sum(count)) %>%
  distinct(word, num_distinct_pairs) %>%
  select(word, num_distinct_pairs)
uni_num_distinct_pairs %>%
  head()
```

Discount we need to spread: $$\lambda(\epsilon) = \frac{\delta\cdot|\{w_{i-1} : C(w_{i-1}w_i) > \delta\}|}{|\{(w\prime, w\prime\prime) : 0 < c(w\prime, w\prime\prime)\}|}$$

```{r}
lambda_epsilon <- vocab %>%
  left_join(cont_counts, by = c("word")) %>%
  left_join(uni_num_distinct_pairs, by = c("word")) %>%
  mutate(discount = ifelse(num_distinct_context > delta, delta, 0),
         p_kn_uni = discount / num_distinct_pairs) %>%
  distinct(word, p_kn_uni)  %>%
  mutate(lambda_epsilon = sum(p_kn_uni)) %>%
  select(word, lambda_epsilon)
lambda_epsilon %>%
  head()
```

Unigram probability: $$p_{KN}(w_i) = \frac{\max(cc_{KN}(w) - \delta, 0)}{|\{(w\prime, w\prime\prime) : 0 < c(w\prime, w\prime\prime)\}|} + \lambda(\epsilon)\frac{1}{|V|}$$

```{r}
#$$p_{KN}(w_i) = \frac{|\{w\prime : 0 < c(w\prime, w_i)\}|}{|\{(w\prime, w\prime\prime) : 0 < c(w\prime, w\prime\prime)\}|}$$
#p_kn_uni_works <- uni_en %>%
#  left_join(uni_distinct_context, by = c("word")) %>%
#  left_join(uni_num_distinct_pairs, by = c("word")) %>%
#  mutate(p_kn_uni = num_distinct_context / num_distinct_pairs) %>%
#  distinct(word, p_kn_uni) %>%
#  select(word, p_kn_uni)

# New
#lambda_epsilon <- 0.4149445 #1/2 - 1/8 + 1/16 - 1/32
V <- nrow(vocab)

p_kn_uni <- vocab %>%
  left_join(cont_counts, by = c("word")) %>%
  left_join(uni_num_distinct_pairs, by = c("word")) %>%
  left_join(lambda_epsilon, by = c("word")) %>%
  mutate(discount = pmax(num_distinct_context - delta, 0),
         p_kn_uni = discount / num_distinct_pairs + (lambda_epsilon / V)) %>%
  distinct(word, p_kn_uni)
p_kn_uni %>%
  head()
```

Tests for true probability distribution:

```{r}
#p_kn_uni_works %>%
#  summarize(total_p = sum(p_kn_uni))
p_kn_uni %>%
  summarize(total_p = sum(p_kn_uni))
```

```{r}
p_kn_uni %>%
  filter(p_kn_uni > 1)
```

## Bigram

```{r}
bi_en <- ex_en %>%
  unnest_tokens(bi, text, token = "ngrams", n = 2) %>%
  mutate(prefix = word(bi, 1),
         word = word(bi, -1)) %>%
  select(-line, -bi)
bi_en %>%
  head()
```

```{r}
bi_en_unk <- bi_en %>%
  distinct(prefix, word) %>%
  mutate(prefix = "_s_unk") %>%
  rbind(data.frame(prefix = "_s_unk", word = "_s_unk"))
bi_en_unk %>%
  head()

bi_en <- bi_en %>%
  rbind(bi_en_unk)
bi_en %>%
  head()
```

Discount: $\max(c_{KN}(w_{i-1}w_i) - \delta, 0)$

```{r}
bi_discounted_counts <- bi_en %>%
  group_by(prefix, word) %>%
  summarize(bi_count = n()) %>%
  mutate(max_prefix_word = pmax(bi_count - delta, 0)) %>%
  select(prefix, word, max_prefix_word)
bi_discounted_counts %>%
  arrange(desc(max_prefix_word)) %>%
  head()
```

Count of prefixes: $c_{KN}(w_{i-n+1}^{i-1})$, for $w_{i-n+1}^w_{i-1} \in V$.

```{r}
bi_all_c_prefix_any <- bi_en %>%
  group_by(prefix) %>%
  summarize(c_prefix_any = n())
bi_all_c_prefix_any %>%
  arrange(desc(c_prefix_any), prefix) %>%
  head()
```

```{r}
bi_distinct_followers <- bi_en %>%
  distinct(prefix, word) %>%
  group_by(prefix) %>%
  summarize(num_distinct_followers = n())
bi_distinct_followers %>%
  arrange(desc(num_distinct_followers), prefix) %>%
  head()
```

```{r}
#p_kn_uni <- vocab %>%
#  left_join(cont_counts, by = c("word")) %>%
#  left_join(uni_num_distinct_pairs, by = c("word")) %>%
#  left_join(lambda_epsilon, by = c("word")) %>%
#  mutate(discount = pmax(num_distinct_context - delta, 0),
#         p_kn_uni = discount / num_distinct_pairs + (lambda_epsilon / V)) %>%
#  distinct(word, p_kn_uni)

p_kn_bi <- bi_en %>%
  left_join(bi_discounted_counts, by = c("prefix", "word")) %>%
  left_join(bi_all_c_prefix_any, by = c("prefix")) %>%
  left_join(bi_distinct_followers, by = c("prefix")) %>%
  left_join(p_kn_uni, by = c("word")) %>%
  mutate(first_term = max_prefix_word / c_prefix_any,
         norm_discount = delta / c_prefix_any,
         num_discounted =  num_distinct_followers,
         normalizing_constant = norm_discount * num_discounted,
         p_kn_bi = first_term + normalizing_constant * p_kn_uni) %>%
  distinct(prefix, word, p_kn_bi, first_term, normalizing_constant, p_kn_uni, norm_discount, num_discounted)
p_kn_bi %>%
  head()
```


Tests for true probability distribution:

```{r}
p_kn_bi %>%
  group_by(word) %>%
  summarize(p = prod(p_kn_bi)) %>%
  head()
```

```{r}
p_kn_bi %>%
  filter(p_kn_bi > 1) %>%
  head()
```

```{r}
p_kn_bi %>%
  filter(prefix == "_s_unk") %>%
  arrange(desc(p_kn_bi))
```

## Trigram

```{r}
tri_en <- ex_en %>%
  unnest_tokens(tri, text, token = "ngrams", n = 3) %>%
  mutate(prefix = word(tri, 1, 2),
         bi = word(tri, 2),
         word = word(tri, -1)) %>%
  select(-line, -tri)
tri_en %>%
  head()
```

```{r}
tri_en_unk <- tri_en %>%
  distinct(bi, word) %>%
  mutate(prefix = paste("_s_unk", bi)) %>%
  rbind(data.frame(prefix = "_s_unk _s_unk", bi = "_s_unk", word = "_s_unk"))
tri_en_unk %>%
  head()

tri_en_unk_unk <- tri_en %>%
  distinct(word) %>%
  mutate(prefix = "_s_unk _s_unk", bi = "_s_unk") %>%
  rbind(data.frame(prefix = "_s_unk _s_unk", bi = "_s_unk", word = "_s_unk"))
tri_en_unk %>%
  head()

tri_en <- tri_en %>%
  rbind(tri_en_unk,
        tri_en_unk_unk)
tri_en %>%
  head()
```

```{r}
tri_discounted_counts <- tri_en %>%
  group_by(prefix, word) %>%
  summarize(c_prefix_word = n()) %>%
  mutate(max_prefix_word = pmax(c_prefix_word - delta, 0)) %>%
  select(prefix, word, max_prefix_word)
tri_discounted_counts %>%
  arrange(prefix, word) %>%
  head()
```

```{r}
tri_all_c_prefix_any <- tri_en %>%
  group_by(prefix) %>%
  summarize(c_prefix_any = n())
tri_all_c_prefix_any %>%
  arrange(desc(c_prefix_any), prefix) %>%
  head()
```

```{r}
tri_distinct_followers <- tri_en %>%
  distinct(prefix, word) %>%
  group_by(prefix) %>%
  summarize(num_distinct_followers = n())
tri_distinct_followers %>%
  arrange(desc(num_distinct_followers), prefix) %>%
  head()
```

```{r}
#tri_occurrences <- tri_en %>%
#  group_by(prefix, word) %>%
#  summarize(sum_c_tris = n())
#tri_occurrences %>%
#  arrange(desc(sum_c_tris))
```

```{r}
#p_kn_tri <- tri_en %>%
#  left_join(tri_discounted_counts, by = c("prefix", "word")) %>%
#  left_join(tri_all_c_prefix_any, by = c("prefix")) %>%
#  left_join(tri_distinct_followers, by = c("prefix")) %>%
#  left_join(tri_occurrences, by = c("prefix", "word")) %>%
#  left_join(p_kn_bi, by = c("bi" = "prefix", "word")) %>%
#  mutate(first_term = max_prefix_word / c_prefix_any,
#         second_term = delta * (num_distinct_followers / sum_c_tris),
#         p_kn_tri = first_term + second_term * p_kn_bi) %>%
#  select(prefix, word, p_kn_bi, p_kn_tri)

p_kn_tri <- tri_en %>%
  left_join(tri_discounted_counts, by = c("prefix", "word")) %>%
  left_join(tri_all_c_prefix_any, by = c("prefix")) %>%
  left_join(tri_distinct_followers, by = c("prefix")) %>%
  left_join(p_kn_bi, by = c("bi" = "prefix", "word")) %>%
  mutate(first_term = max_prefix_word / c_prefix_any,
         norm_discount = delta / c_prefix_any,
         num_discounted = num_distinct_followers,
         normalizing_constant = norm_discount * num_discounted,
         p_kn_tri = first_term + normalizing_constant * p_kn_bi) %>%
  distinct(prefix, bi, word, p_kn_tri, first_term, normalizing_constant, p_kn_bi)
p_kn_tri %>%
  head()
```

```{r}
p_kn_tri %>%
  group_by(word) %>%
  summarize(p = prod(p_kn_tri)) %>%
  head()
```

```{r}
p_kn_tri %>%
  filter(p_kn_tri > 1) %>%
  head()
```

```{r}
p_kn_tri %>%
  filter(word == "if") %>%
  arrange(desc(p_kn_tri))
```

```{r}
p_kn_tri %>%
  filter(word == "of") %>%
  arrange(desc(p_kn_tri))
```

What if user typed "I need a head of ..."?

```{r}
p_kn_tri %>%
  filter(prefix == "a head") %>%
  arrange(desc(p_kn_tri))
```

```{r}
p_kn_tri %>%
  filter((prefix == "a head" | prefix == "_s_unk head" | prefix == "_s_unk _s_unk") & word != "_s_unk") %>%
  arrange(desc(p_kn_tri))
```

```{r}
p_kn_tri %>%
  filter(str_detect(prefix, "_s_unk head")) %>%
  arrange(desc(p_kn_tri))
```

```{r}
p_kn_tri %>%
  filter(bi == "_s_unk") %>%
  arrange(desc(p_kn_tri))
```

## Quadgram

```{r}
quad_en <- ex_en %>%
  unnest_tokens(quad, text, token = "ngrams", n = 4) %>%
  mutate(prefix = word(quad, 1, 3),
         bi = word(quad, 2, 3),
         word = word(quad, -1)) %>%
  select(-line, -quad)
quad_en
```

Discounted count of times word follows prefix: $max(c(w_{i-n+1}^{i-1}, w_i) - \delta, 0)$

```{r}
quad_discounted_counts <- quad_en %>%
  group_by(prefix, word) %>%
  summarize(c_prefix_word = n()) %>%
  mutate(max_prefix_word = pmax(c_prefix_word - delta, 0)) %>%
  select(-c_prefix_word)
quad_discounted_counts %>%
  arrange(prefix, word)
```

Sum of counts of times any word follows prefix: $\sum_{w\prime}c(w_{i-1},w\prime)$

```{r}
quad_all_c_prefix_any <- quad_en %>%
  group_by(prefix) %>%
  summarize(c_prefix_any = n()) %>%
  arrange(desc(c_prefix_any), prefix)
quad_all_c_prefix_any
```

Number of distinct words occurring after some prefix: $|\{w\prime : 0 < c(w_{i-n+1}^{i-1}, w\prime)\}|$

```{r}
quad_distinct_followers <- quad_en %>%
  distinct(prefix, word) %>%
  group_by(prefix) %>%
  summarize(num_distinct_followers = n())
quad_distinct_followers %>%
  arrange(desc(num_distinct_followers), prefix)
```

Number of times quad appears (per word): $\sum_{w_i}c(w_{i-n+1}^{i-1})$

```{r}
quad_occurrences <- quad_en %>%
  group_by(prefix, word) %>%
  summarize(sum_c_quads = n())
quad_occurrences %>%
  arrange(desc(sum_c_quads))
```

Kneser-Ney smoothed probability: $$p_{KN}(w_i | w_{i-n+1}^{i-1}) = \frac{max(c(w_{i-n+1}^{i-1}, w_i) - \delta, 0)}{\sum_{w\prime}c(w_{i-1},w\prime)} + \delta\frac{|\{w\prime : 0 < c(w_{i-n+1}^{i-1}, w\prime)\}|}{\sum_{w_i}c(w_{i-n+1}^{i})}$$

```{r}
p_kn_quad <- quad_en %>%
  left_join(quad_discounted_counts, by = c("prefix", "word")) %>%
  left_join(quad_all_c_prefix_any, by = c("prefix")) %>%
  left_join(quad_distinct_followers, by = c("prefix")) %>%
  left_join(quad_occurrences, by = c("prefix", "word")) %>%
  left_join(p_kn_tri, by = c("bi" = "prefix", "word")) %>%
  mutate(first_term = max_prefix_word / c_prefix_any,
         second_term = delta * (num_distinct_followers / sum_c_quads),
         p_kn_quad = first_term + second_term * p_kn_tri) %>%
  select(prefix, bi, word, p_kn_tri, p_kn_quad)
p_kn_quad
```


